{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abakamousa/NER-Sangkak-challenge/blob/0.1/training/experimentations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install librairies"
      ],
      "metadata": {
        "id": "Ib-uJVw2-Os8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall typing -y\n",
        "!pip install flair==0.9"
      ],
      "metadata": {
        "id": "ThK2HRmOagES",
        "outputId": "74a8c5d1-e212-49a8-c101-b83d6fefe98d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping typing as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flair==0.9\n",
            "  Using cached flair-0.9-py3-none-any.whl (319 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from flair==0.9) (1.0.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from flair==0.9) (2022.6.2)\n",
            "Requirement already satisfied: sentencepiece==0.1.95 in /usr/local/lib/python3.8/dist-packages (from flair==0.9) (0.1.95)\n",
            "Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from flair==0.9) (2.1.0)\n",
            "Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.8/dist-packages (from flair==0.9) (1.5.11)\n",
            "Requirement already satisfied: more-itertools~=8.8.0 in /usr/local/lib/python3.8/dist-packages (from flair==0.9) (8.8.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from flair==0.9) (4.9.2)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.8/dist-packages (from flair==0.9) (1.0.9)\n",
            "Requirement already satisfied: konoha<5.0.0,>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from flair==0.9) (4.6.5)\n",
            "Requirement already satisfied: bpemb>=0.3.2 in /usr/local/lib/python3.8/dist-packages (from flair==0.9) (0.3.4)\n",
            "Requirement already satisfied: mpld3==0.3 in /usr/local/lib/python3.8/dist-packages (from flair==0.9) (0.3)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from flair==0.9) (1.13.1+cu116)\n",
            "Requirement already satisfied: wikipedia-api in /usr/local/lib/python3.8/dist-packages (from flair==0.9) (0.5.8)\n",
            "Requirement already satisfied: transformers>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from flair==0.9) (4.26.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.8/dist-packages (from flair==0.9) (6.1.1)\n",
            "Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.8/dist-packages (from flair==0.9) (1.2.13)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.8/dist-packages (from flair==0.9) (2.8.2)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.8/dist-packages (from flair==0.9) (4.64.1)\n",
            "Requirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from flair==0.9) (3.6.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from flair==0.9) (0.8.10)\n",
            "Requirement already satisfied: janome in /usr/local/lib/python3.8/dist-packages (from flair==0.9) (0.4.2)\n",
            "Requirement already satisfied: gdown==3.12.2 in /usr/local/lib/python3.8/dist-packages (from flair==0.9) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.8/dist-packages (from flair==0.9) (0.12.1)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.8/dist-packages (from flair==0.9) (3.5.3)\n",
            "Requirement already satisfied: conllu>=4.0 in /usr/local/lib/python3.8/dist-packages (from flair==0.9) (4.5.2)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from flair==0.9) (0.2.7)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown==3.12.2->flair==0.9) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown==3.12.2->flair==0.9) (3.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown==3.12.2->flair==0.9) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from bpemb>=0.3.2->flair==0.9) (1.22.4)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.8/dist-packages (from deprecated>=1.2.4->flair==0.9) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from gensim<=3.8.3,>=3.4.0->flair==0.9) (1.7.3)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim<=3.8.3,>=3.4.0->flair==0.9) (6.3.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from hyperopt>=0.1.1->flair==0.9) (2.2.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from hyperopt>=0.1.1->flair==0.9) (3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from hyperopt>=0.1.1->flair==0.9) (0.16.0)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.8/dist-packages (from hyperopt>=0.1.1->flair==0.9) (0.10.9.7)\n",
            "Requirement already satisfied: importlib-metadata<4.0.0,>=3.7.0 in /usr/local/lib/python3.8/dist-packages (from konoha<5.0.0,>=4.0.0->flair==0.9) (3.10.1)\n",
            "Requirement already satisfied: overrides<4.0.0,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from konoha<5.0.0,>=4.0.0->flair==0.9) (3.1.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2.3->flair==0.9) (8.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2.3->flair==0.9) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2.3->flair==0.9) (4.38.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2.3->flair==0.9) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2.3->flair==0.9) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2.3->flair==0.9) (23.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->flair==0.9) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->flair==0.9) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch!=1.8,>=1.5.0->flair==0.9) (4.5.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.0.0->flair==0.9) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.0.0->flair==0.9) (0.13.2)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.8/dist-packages (from ftfy->flair==0.9) (0.2.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair==0.9) (3.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown==3.12.2->flair==0.9) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown==3.12.2->flair==0.9) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown==3.12.2->flair==0.9) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown==3.12.2->flair==0.9) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown==3.12.2->flair==0.9) (1.7.1)\n",
            "Installing collected packages: flair\n",
            "Successfully installed flair-0.9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "flair"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install flair\n",
        "#!pip uninstall flair\n"
      ],
      "metadata": {
        "id": "CErtxjRi9-9q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import librairies"
      ],
      "metadata": {
        "id": "87-SFPnO-XWV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_uBvk_eXDEyb"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "\n",
        "\n",
        "import flair\n",
        "from typing import List\n",
        "from flair.trainers import ModelTrainer\n",
        "from flair.models import SequenceTagger\n",
        "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, FlairEmbeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define columns\n",
        "columns = {0 : 'text', 1 : 'ner'}# directory where the data resides\n",
        "data_folder = '/content/bbj/'# initializing the corpus\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file = 'train.txt',\n",
        "                              test_file = 'test.txt',\n",
        "                              dev_file = 'dev.txt')"
      ],
      "metadata": {
        "id": "t40jeM7i8V29",
        "outputId": "b7e9ca5e-e1e9-48f8-b76a-c7848e4e71df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-01 18:27:43,617 Reading data from /content/bbj\n",
            "2023-03-01 18:27:43,640 Train: /content/bbj/train.txt\n",
            "2023-03-01 18:27:43,643 Dev: /content/bbj/dev.txt\n",
            "2023-03-01 18:27:43,644 Test: /content/bbj/test.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(corpus.train))"
      ],
      "metadata": {
        "id": "5qk71Vxq-tTv",
        "outputId": "8bc33558-868e-409d-cedc-cf582c4a3466",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus.train[0].to_tagged_string('ner'))"
      ],
      "metadata": {
        "id": "6COt-lm7_DZp",
        "outputId": "047074b1-f7a7-4418-d713-b8f66358dfcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: \"Msaʼnyə̂ gɔtí cyətə nə́ bǎyá cyə́ nəjí pôʼ bǎhə́lə́\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "20I1OeMJbDDA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag_type = 'ner'\n",
        "\n",
        "#  make the tag dictionary from the corpus\n",
        "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)"
      ],
      "metadata": {
        "id": "GpF4syD4_foa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UH3bCAiOcrH5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_types = [\n",
        "\n",
        "    WordEmbeddings('glove'),\n",
        "\n",
        "    # comment in this line to use character embeddings\n",
        "    # CharacterEmbeddings(),\n",
        "\n",
        "    # comment in these lines to use flair embeddings\n",
        "    # FlairEmbeddings('news-forward'),\n",
        "    # FlairEmbeddings('news-backward'),\n",
        "]"
      ],
      "metadata": {
        "id": "xNTq9RFddo7-",
        "outputId": "8c535991-294a-4637-a8d2-ac46557ac859",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-01 18:37:20,181 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmpfdv5ms6k\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 160000128/160000128 [00:09<00:00, 17705922.31B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-01 18:37:29,593 copying /tmp/tmpfdv5ms6k to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-01 18:37:30,138 removing temp file /tmp/tmpfdv5ms6k\n",
            "2023-03-01 18:37:30,565 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim not found in cache, downloading to /tmp/tmp61iffboy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21494764/21494764 [00:01<00:00, 12302651.15B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-01 18:37:32,689 copying /tmp/tmp61iffboy to cache at /root/.flair/embeddings/glove.gensim\n",
            "2023-03-01 18:37:32,724 removing temp file /tmp/tmp61iffboy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = StackedEmbeddings(embeddings=embedding_types)\n",
        "\n",
        "# initialize sequence tagger\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=tag_dictionary,\n",
        "                        tag_type=tag_type,\n",
        "                        use_crf=True)\n",
        "\n",
        "# initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# start training\n",
        "trainer.train('resources/taggers/example-upos',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=10)"
      ],
      "metadata": {
        "id": "yAfBBZlCdnPm",
        "outputId": "77795c91-6190-42ce-b308-4e7493b634ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-01 18:58:05,599 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 18:58:05,602 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings('glove')\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (rnn): LSTM(100, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=11, bias=True)\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2023-03-01 18:58:05,605 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 18:58:05,608 Corpus: \"Corpus: 3384 train + 483 dev + 966 test sentences\"\n",
            "2023-03-01 18:58:05,610 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 18:58:05,612 Parameters:\n",
            "2023-03-01 18:58:05,614  - learning_rate: \"0.1\"\n",
            "2023-03-01 18:58:05,616  - mini_batch_size: \"32\"\n",
            "2023-03-01 18:58:05,617  - patience: \"3\"\n",
            "2023-03-01 18:58:05,619  - anneal_factor: \"0.5\"\n",
            "2023-03-01 18:58:05,620  - max_epochs: \"10\"\n",
            "2023-03-01 18:58:05,621  - shuffle: \"True\"\n",
            "2023-03-01 18:58:05,623  - train_with_dev: \"False\"\n",
            "2023-03-01 18:58:05,624  - batch_growth_annealing: \"False\"\n",
            "2023-03-01 18:58:05,625 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 18:58:05,627 Model training base path: \"resources/taggers/example-upos\"\n",
            "2023-03-01 18:58:05,629 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 18:58:05,630 Device: cpu\n",
            "2023-03-01 18:58:05,632 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 18:58:05,633 Embeddings storage mode: cpu\n",
            "2023-03-01 18:58:05,636 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 18:58:07,367 epoch 1 - iter 10/106 - loss 1.12542163 - samples/sec: 185.40 - lr: 0.100000\n",
            "2023-03-01 18:58:09,617 epoch 1 - iter 20/106 - loss 0.81897615 - samples/sec: 142.51 - lr: 0.100000\n",
            "2023-03-01 18:58:12,103 epoch 1 - iter 30/106 - loss 0.68666501 - samples/sec: 129.00 - lr: 0.100000\n",
            "2023-03-01 18:58:14,124 epoch 1 - iter 40/106 - loss 0.64653346 - samples/sec: 158.92 - lr: 0.100000\n",
            "2023-03-01 18:58:15,404 epoch 1 - iter 50/106 - loss 0.65343445 - samples/sec: 250.80 - lr: 0.100000\n",
            "2023-03-01 18:58:16,934 epoch 1 - iter 60/106 - loss 0.61259437 - samples/sec: 209.68 - lr: 0.100000\n",
            "2023-03-01 18:58:18,572 epoch 1 - iter 70/106 - loss 0.58329551 - samples/sec: 195.93 - lr: 0.100000\n",
            "2023-03-01 18:58:20,144 epoch 1 - iter 80/106 - loss 0.55370256 - samples/sec: 204.06 - lr: 0.100000\n",
            "2023-03-01 18:58:21,769 epoch 1 - iter 90/106 - loss 0.53380746 - samples/sec: 197.41 - lr: 0.100000\n",
            "2023-03-01 18:58:23,718 epoch 1 - iter 100/106 - loss 0.51222407 - samples/sec: 164.46 - lr: 0.100000\n",
            "2023-03-01 18:58:25,284 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 18:58:25,290 EPOCH 1 done: loss 0.4965 - lr 0.1000000\n",
            "2023-03-01 18:58:27,239 DEV : loss 0.30118200182914734 - f1-score (micro avg)  0.1043\n",
            "2023-03-01 18:58:27,318 BAD EPOCHS (no improvement): 0\n",
            "2023-03-01 18:58:27,321 saving best model\n",
            "2023-03-01 18:58:34,847 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 18:58:36,575 epoch 2 - iter 10/106 - loss 0.38270366 - samples/sec: 185.66 - lr: 0.100000\n",
            "2023-03-01 18:58:38,154 epoch 2 - iter 20/106 - loss 0.36768679 - samples/sec: 203.23 - lr: 0.100000\n",
            "2023-03-01 18:58:41,887 epoch 2 - iter 30/106 - loss 0.35551343 - samples/sec: 85.85 - lr: 0.100000\n",
            "2023-03-01 18:58:44,445 epoch 2 - iter 40/106 - loss 0.36039956 - samples/sec: 125.56 - lr: 0.100000\n",
            "2023-03-01 18:58:48,015 epoch 2 - iter 50/106 - loss 0.35397217 - samples/sec: 89.87 - lr: 0.100000\n",
            "2023-03-01 18:58:49,963 epoch 2 - iter 60/106 - loss 0.34974007 - samples/sec: 165.07 - lr: 0.100000\n",
            "2023-03-01 18:58:51,525 epoch 2 - iter 70/106 - loss 0.34181547 - samples/sec: 205.45 - lr: 0.100000\n",
            "2023-03-01 18:58:53,179 epoch 2 - iter 80/106 - loss 0.33937167 - samples/sec: 193.99 - lr: 0.100000\n",
            "2023-03-01 18:58:54,756 epoch 2 - iter 90/106 - loss 0.33792225 - samples/sec: 203.37 - lr: 0.100000\n",
            "2023-03-01 18:58:56,409 epoch 2 - iter 100/106 - loss 0.33672283 - samples/sec: 194.02 - lr: 0.100000\n",
            "2023-03-01 18:58:57,359 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 18:58:57,361 EPOCH 2 done: loss 0.3342 - lr 0.1000000\n",
            "2023-03-01 18:58:59,689 DEV : loss 0.27283039689064026 - f1-score (micro avg)  0.1171\n",
            "2023-03-01 18:58:59,742 BAD EPOCHS (no improvement): 0\n",
            "2023-03-01 18:58:59,754 saving best model\n",
            "2023-03-01 18:59:08,368 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 18:59:10,013 epoch 3 - iter 10/106 - loss 0.29862534 - samples/sec: 195.94 - lr: 0.100000\n",
            "2023-03-01 18:59:11,689 epoch 3 - iter 20/106 - loss 0.30448936 - samples/sec: 191.45 - lr: 0.100000\n",
            "2023-03-01 18:59:13,348 epoch 3 - iter 30/106 - loss 0.31102430 - samples/sec: 193.50 - lr: 0.100000\n",
            "2023-03-01 18:59:15,652 epoch 3 - iter 40/106 - loss 0.30953108 - samples/sec: 139.28 - lr: 0.100000\n",
            "2023-03-01 18:59:18,096 epoch 3 - iter 50/106 - loss 0.31196901 - samples/sec: 131.21 - lr: 0.100000\n",
            "2023-03-01 18:59:20,246 epoch 3 - iter 60/106 - loss 0.30262574 - samples/sec: 149.60 - lr: 0.100000\n",
            "2023-03-01 18:59:21,841 epoch 3 - iter 70/106 - loss 0.29887401 - samples/sec: 201.18 - lr: 0.100000\n",
            "2023-03-01 18:59:23,473 epoch 3 - iter 80/106 - loss 0.30107055 - samples/sec: 196.50 - lr: 0.100000\n",
            "2023-03-01 18:59:25,190 epoch 3 - iter 90/106 - loss 0.30144468 - samples/sec: 186.90 - lr: 0.100000\n",
            "2023-03-01 18:59:26,855 epoch 3 - iter 100/106 - loss 0.30139608 - samples/sec: 192.67 - lr: 0.100000\n",
            "2023-03-01 18:59:27,743 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 18:59:27,745 EPOCH 3 done: loss 0.3005 - lr 0.1000000\n",
            "2023-03-01 18:59:28,910 DEV : loss 0.25158393383026123 - f1-score (micro avg)  0.1528\n",
            "2023-03-01 18:59:28,939 BAD EPOCHS (no improvement): 0\n",
            "2023-03-01 18:59:28,941 saving best model\n",
            "2023-03-01 18:59:37,904 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 18:59:39,583 epoch 4 - iter 10/106 - loss 0.29395616 - samples/sec: 191.89 - lr: 0.100000\n",
            "2023-03-01 18:59:41,165 epoch 4 - iter 20/106 - loss 0.29703536 - samples/sec: 202.99 - lr: 0.100000\n",
            "2023-03-01 18:59:42,790 epoch 4 - iter 30/106 - loss 0.29736842 - samples/sec: 197.45 - lr: 0.100000\n",
            "2023-03-01 18:59:44,489 epoch 4 - iter 40/106 - loss 0.28609539 - samples/sec: 188.76 - lr: 0.100000\n",
            "2023-03-01 18:59:46,496 epoch 4 - iter 50/106 - loss 0.27996234 - samples/sec: 159.80 - lr: 0.100000\n",
            "2023-03-01 18:59:48,881 epoch 4 - iter 60/106 - loss 0.28359377 - samples/sec: 134.80 - lr: 0.100000\n",
            "2023-03-01 18:59:51,304 epoch 4 - iter 70/106 - loss 0.28321417 - samples/sec: 132.54 - lr: 0.100000\n",
            "2023-03-01 18:59:52,967 epoch 4 - iter 80/106 - loss 0.28339372 - samples/sec: 193.21 - lr: 0.100000\n",
            "2023-03-01 18:59:54,587 epoch 4 - iter 90/106 - loss 0.28585419 - samples/sec: 198.04 - lr: 0.100000\n",
            "2023-03-01 18:59:56,163 epoch 4 - iter 100/106 - loss 0.28639228 - samples/sec: 203.52 - lr: 0.100000\n",
            "2023-03-01 18:59:57,189 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 18:59:57,192 EPOCH 4 done: loss 0.2852 - lr 0.1000000\n",
            "2023-03-01 18:59:58,326 DEV : loss 0.2479986995458603 - f1-score (micro avg)  0.1589\n",
            "2023-03-01 18:59:58,353 BAD EPOCHS (no improvement): 0\n",
            "2023-03-01 18:59:58,356 saving best model\n",
            "2023-03-01 19:00:07,173 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 19:00:08,860 epoch 5 - iter 10/106 - loss 0.25403055 - samples/sec: 190.30 - lr: 0.100000\n",
            "2023-03-01 19:00:10,517 epoch 5 - iter 20/106 - loss 0.25629978 - samples/sec: 193.67 - lr: 0.100000\n",
            "2023-03-01 19:00:12,227 epoch 5 - iter 30/106 - loss 0.25990735 - samples/sec: 187.50 - lr: 0.100000\n",
            "2023-03-01 19:00:13,898 epoch 5 - iter 40/106 - loss 0.26573876 - samples/sec: 192.08 - lr: 0.100000\n",
            "2023-03-01 19:00:15,562 epoch 5 - iter 50/106 - loss 0.26801070 - samples/sec: 192.68 - lr: 0.100000\n",
            "2023-03-01 19:00:17,187 epoch 5 - iter 60/106 - loss 0.27016956 - samples/sec: 197.40 - lr: 0.100000\n",
            "2023-03-01 19:00:19,375 epoch 5 - iter 70/106 - loss 0.27412809 - samples/sec: 146.56 - lr: 0.100000\n",
            "2023-03-01 19:00:21,890 epoch 5 - iter 80/106 - loss 0.27795948 - samples/sec: 127.55 - lr: 0.100000\n",
            "2023-03-01 19:00:24,006 epoch 5 - iter 90/106 - loss 0.27708110 - samples/sec: 151.95 - lr: 0.100000\n",
            "2023-03-01 19:00:25,669 epoch 5 - iter 100/106 - loss 0.27716781 - samples/sec: 192.86 - lr: 0.100000\n",
            "2023-03-01 19:00:26,587 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 19:00:26,589 EPOCH 5 done: loss 0.2768 - lr 0.1000000\n",
            "2023-03-01 19:00:27,716 DEV : loss 0.26271846890449524 - f1-score (micro avg)  0.1929\n",
            "2023-03-01 19:00:27,746 BAD EPOCHS (no improvement): 0\n",
            "2023-03-01 19:00:27,748 saving best model\n",
            "2023-03-01 19:00:34,191 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 19:00:36,477 epoch 6 - iter 10/106 - loss 0.24908830 - samples/sec: 140.62 - lr: 0.100000\n",
            "2023-03-01 19:00:38,974 epoch 6 - iter 20/106 - loss 0.26602032 - samples/sec: 128.44 - lr: 0.100000\n",
            "2023-03-01 19:00:40,733 epoch 6 - iter 30/106 - loss 0.27437605 - samples/sec: 183.01 - lr: 0.100000\n",
            "2023-03-01 19:00:42,491 epoch 6 - iter 40/106 - loss 0.27906859 - samples/sec: 182.43 - lr: 0.100000\n",
            "2023-03-01 19:00:44,240 epoch 6 - iter 50/106 - loss 0.27840369 - samples/sec: 183.47 - lr: 0.100000\n",
            "2023-03-01 19:00:45,888 epoch 6 - iter 60/106 - loss 0.27666888 - samples/sec: 194.64 - lr: 0.100000\n",
            "2023-03-01 19:00:47,474 epoch 6 - iter 70/106 - loss 0.27540934 - samples/sec: 202.28 - lr: 0.100000\n",
            "2023-03-01 19:00:49,121 epoch 6 - iter 80/106 - loss 0.27579251 - samples/sec: 194.83 - lr: 0.100000\n",
            "2023-03-01 19:00:51,441 epoch 6 - iter 90/106 - loss 0.27248083 - samples/sec: 138.42 - lr: 0.100000\n",
            "2023-03-01 19:00:53,765 epoch 6 - iter 100/106 - loss 0.27543332 - samples/sec: 138.35 - lr: 0.100000\n",
            "2023-03-01 19:00:55,183 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 19:00:55,186 EPOCH 6 done: loss 0.2736 - lr 0.1000000\n",
            "2023-03-01 19:00:56,355 DEV : loss 0.2330288290977478 - f1-score (micro avg)  0.1863\n",
            "2023-03-01 19:00:56,382 BAD EPOCHS (no improvement): 1\n",
            "2023-03-01 19:00:56,384 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 19:00:58,243 epoch 7 - iter 10/106 - loss 0.26772617 - samples/sec: 173.14 - lr: 0.100000\n",
            "2023-03-01 19:00:59,820 epoch 7 - iter 20/106 - loss 0.25841393 - samples/sec: 203.43 - lr: 0.100000\n",
            "2023-03-01 19:01:01,497 epoch 7 - iter 30/106 - loss 0.26162079 - samples/sec: 191.29 - lr: 0.100000\n",
            "2023-03-01 19:01:03,214 epoch 7 - iter 40/106 - loss 0.27034830 - samples/sec: 186.79 - lr: 0.100000\n",
            "2023-03-01 19:01:04,836 epoch 7 - iter 50/106 - loss 0.27142528 - samples/sec: 197.81 - lr: 0.100000\n",
            "2023-03-01 19:01:06,965 epoch 7 - iter 60/106 - loss 0.26802171 - samples/sec: 150.58 - lr: 0.100000\n",
            "2023-03-01 19:01:09,310 epoch 7 - iter 70/106 - loss 0.27217220 - samples/sec: 137.02 - lr: 0.100000\n",
            "2023-03-01 19:01:11,668 epoch 7 - iter 80/106 - loss 0.26722371 - samples/sec: 136.27 - lr: 0.100000\n",
            "2023-03-01 19:01:13,284 epoch 7 - iter 90/106 - loss 0.26818543 - samples/sec: 198.69 - lr: 0.100000\n",
            "2023-03-01 19:01:14,943 epoch 7 - iter 100/106 - loss 0.26812025 - samples/sec: 193.31 - lr: 0.100000\n",
            "2023-03-01 19:01:15,949 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 19:01:15,952 EPOCH 7 done: loss 0.2675 - lr 0.1000000\n",
            "2023-03-01 19:01:17,066 DEV : loss 0.23828430473804474 - f1-score (micro avg)  0.1452\n",
            "2023-03-01 19:01:17,094 BAD EPOCHS (no improvement): 2\n",
            "2023-03-01 19:01:17,097 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 19:01:18,810 epoch 8 - iter 10/106 - loss 0.25100621 - samples/sec: 187.87 - lr: 0.100000\n",
            "2023-03-01 19:01:20,459 epoch 8 - iter 20/106 - loss 0.25686199 - samples/sec: 194.69 - lr: 0.100000\n",
            "2023-03-01 19:01:22,384 epoch 8 - iter 30/106 - loss 0.25217259 - samples/sec: 166.54 - lr: 0.100000\n",
            "2023-03-01 19:01:24,810 epoch 8 - iter 40/106 - loss 0.25365522 - samples/sec: 132.20 - lr: 0.100000\n",
            "2023-03-01 19:01:27,293 epoch 8 - iter 50/106 - loss 0.25601017 - samples/sec: 129.35 - lr: 0.100000\n",
            "2023-03-01 19:01:28,981 epoch 8 - iter 60/106 - loss 0.26130903 - samples/sec: 189.94 - lr: 0.100000\n",
            "2023-03-01 19:01:30,752 epoch 8 - iter 70/106 - loss 0.26363829 - samples/sec: 181.16 - lr: 0.100000\n",
            "2023-03-01 19:01:32,440 epoch 8 - iter 80/106 - loss 0.26196603 - samples/sec: 190.00 - lr: 0.100000\n",
            "2023-03-01 19:01:34,095 epoch 8 - iter 90/106 - loss 0.26235476 - samples/sec: 193.83 - lr: 0.100000\n",
            "2023-03-01 19:01:35,853 epoch 8 - iter 100/106 - loss 0.26351535 - samples/sec: 182.50 - lr: 0.100000\n",
            "2023-03-01 19:01:36,800 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 19:01:36,802 EPOCH 8 done: loss 0.2637 - lr 0.1000000\n",
            "2023-03-01 19:01:38,344 DEV : loss 0.23748840391635895 - f1-score (micro avg)  0.1957\n",
            "2023-03-01 19:01:38,392 BAD EPOCHS (no improvement): 0\n",
            "2023-03-01 19:01:38,397 saving best model\n",
            "2023-03-01 19:01:46,813 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 19:01:48,424 epoch 9 - iter 10/106 - loss 0.26264662 - samples/sec: 200.06 - lr: 0.100000\n",
            "2023-03-01 19:01:50,082 epoch 9 - iter 20/106 - loss 0.25665121 - samples/sec: 193.45 - lr: 0.100000\n",
            "2023-03-01 19:01:51,705 epoch 9 - iter 30/106 - loss 0.26478606 - samples/sec: 197.65 - lr: 0.100000\n",
            "2023-03-01 19:01:53,475 epoch 9 - iter 40/106 - loss 0.26970656 - samples/sec: 181.27 - lr: 0.100000\n",
            "2023-03-01 19:01:55,731 epoch 9 - iter 50/106 - loss 0.27055640 - samples/sec: 142.47 - lr: 0.100000\n",
            "2023-03-01 19:01:58,069 epoch 9 - iter 60/106 - loss 0.27051232 - samples/sec: 137.36 - lr: 0.100000\n",
            "2023-03-01 19:02:00,155 epoch 9 - iter 70/106 - loss 0.26569253 - samples/sec: 153.85 - lr: 0.100000\n",
            "2023-03-01 19:02:01,799 epoch 9 - iter 80/106 - loss 0.26504969 - samples/sec: 195.14 - lr: 0.100000\n",
            "2023-03-01 19:02:03,642 epoch 9 - iter 90/106 - loss 0.26255249 - samples/sec: 174.03 - lr: 0.100000\n",
            "2023-03-01 19:02:05,312 epoch 9 - iter 100/106 - loss 0.26378589 - samples/sec: 192.12 - lr: 0.100000\n",
            "2023-03-01 19:02:06,266 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 19:02:06,268 EPOCH 9 done: loss 0.2640 - lr 0.1000000\n",
            "2023-03-01 19:02:07,391 DEV : loss 0.22640591859817505 - f1-score (micro avg)  0.2009\n",
            "2023-03-01 19:02:07,418 BAD EPOCHS (no improvement): 0\n",
            "2023-03-01 19:02:07,420 saving best model\n",
            "2023-03-01 19:02:16,338 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 19:02:17,929 epoch 10 - iter 10/106 - loss 0.29687041 - samples/sec: 201.97 - lr: 0.100000\n",
            "2023-03-01 19:02:19,665 epoch 10 - iter 20/106 - loss 0.26362932 - samples/sec: 184.82 - lr: 0.100000\n",
            "2023-03-01 19:02:21,202 epoch 10 - iter 30/106 - loss 0.25987955 - samples/sec: 208.83 - lr: 0.100000\n",
            "2023-03-01 19:02:22,941 epoch 10 - iter 40/106 - loss 0.26337772 - samples/sec: 185.00 - lr: 0.100000\n",
            "2023-03-01 19:02:24,553 epoch 10 - iter 50/106 - loss 0.26488858 - samples/sec: 199.26 - lr: 0.100000\n",
            "2023-03-01 19:02:26,821 epoch 10 - iter 60/106 - loss 0.26561177 - samples/sec: 141.42 - lr: 0.100000\n",
            "2023-03-01 19:02:29,112 epoch 10 - iter 70/106 - loss 0.26287911 - samples/sec: 139.99 - lr: 0.100000\n",
            "2023-03-01 19:02:31,286 epoch 10 - iter 80/106 - loss 0.26408003 - samples/sec: 147.66 - lr: 0.100000\n",
            "2023-03-01 19:02:32,899 epoch 10 - iter 90/106 - loss 0.26146163 - samples/sec: 198.84 - lr: 0.100000\n",
            "2023-03-01 19:02:34,720 epoch 10 - iter 100/106 - loss 0.25946884 - samples/sec: 176.11 - lr: 0.100000\n",
            "2023-03-01 19:02:35,775 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 19:02:35,777 EPOCH 10 done: loss 0.2590 - lr 0.1000000\n",
            "2023-03-01 19:02:37,474 DEV : loss 0.2274715155363083 - f1-score (micro avg)  0.2218\n",
            "2023-03-01 19:02:37,501 BAD EPOCHS (no improvement): 0\n",
            "2023-03-01 19:02:37,503 saving best model\n",
            "2023-03-01 19:02:52,499 ----------------------------------------------------------------------------------------------------\n",
            "2023-03-01 19:02:52,502 loading file resources/taggers/example-upos/best-model.pt\n",
            "2023-03-01 19:02:56,786 0.5927\t0.2462\t0.3479\t0.2113\n",
            "2023-03-01 19:02:56,792 \n",
            "Results:\n",
            "- F-score (micro) 0.3479\n",
            "- F-score (macro) 0.2853\n",
            "- Accuracy 0.2113\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         PER     0.6171    0.4160    0.4970       399\n",
            "        DATE     0.4959    0.3389    0.4026       180\n",
            "         LOC     0.7000    0.0820    0.1469       256\n",
            "         ORG     0.7333    0.0507    0.0948       217\n",
            "\n",
            "   micro avg     0.5927    0.2462    0.3479      1052\n",
            "   macro avg     0.6366    0.2219    0.2853      1052\n",
            "weighted avg     0.6405    0.2462    0.3127      1052\n",
            " samples avg     0.2113    0.2113    0.2113      1052\n",
            "\n",
            "2023-03-01 19:02:56,794 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_score': 0.34788448623237067,\n",
              " 'dev_score_history': [0.1042654028436019,\n",
              "  0.11707317073170732,\n",
              "  0.15277777777777776,\n",
              "  0.15894039735099338,\n",
              "  0.1928721174004193,\n",
              "  0.18625277161862527,\n",
              "  0.14519906323185014,\n",
              "  0.1957446808510638,\n",
              "  0.20085470085470084,\n",
              "  0.22175732217573227],\n",
              " 'train_loss_history': [0.49650019372321375,\n",
              "  0.334163578315841,\n",
              "  0.30047492025647465,\n",
              "  0.28519932501337114,\n",
              "  0.2768273296746643,\n",
              "  0.2735706666005516,\n",
              "  0.26747085068035537,\n",
              "  0.26372328438275644,\n",
              "  0.26400615421050405,\n",
              "  0.25898311131036705],\n",
              " 'dev_loss_history': [tensor(0.3012),\n",
              "  tensor(0.2728),\n",
              "  tensor(0.2516),\n",
              "  tensor(0.2480),\n",
              "  tensor(0.2627),\n",
              "  tensor(0.2330),\n",
              "  tensor(0.2383),\n",
              "  tensor(0.2375),\n",
              "  tensor(0.2264),\n",
              "  tensor(0.2275)]}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}